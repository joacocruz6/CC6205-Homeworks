{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:30:18.109327Z",
     "start_time": "2020-03-19T18:30:18.103344Z"
    },
    "colab_type": "text",
    "id": "q5CSRY4oNCHK"
   },
   "source": [
    "\n",
    "# Minitarea 3\n",
    "\n",
    "\n",
    "-----------------\n",
    "\n",
    "Nombre: Joaquin Cruz\n",
    "\n",
    "Fecha de Entrega: Domingo 17 de Mayo\n",
    "\n",
    "\n",
    "## Instrucciones\n",
    "\n",
    "- El ejercicio consiste en:\n",
    "\n",
    "    - Responder preguntas relativas a los contenidos vistos en los vídeos y slides de las clases. \n",
    "    \n",
    "    - Entrenar Word2Vec y FastText sobre un pequeño corpus.\n",
    "    \n",
    "    - Evaluar los embeddings obtenidos en una tarea de clasificación.\n",
    "\n",
    "- La minitarea es INDIVIDUAL.\n",
    "\n",
    "- Está demás decir que no se admiten copias, ni de código, ni de respuestas escritas. \n",
    "\n",
    "- La entrega debe ser por u-cursos.\n",
    "\n",
    "- Atrasos: se descontará un punto por día hábil de atraso tanto para las mini-tareas como para las competencias.\n",
    "\n",
    "- En el horario de auxiliar se abrirán horarios de consulta en donde podrán preguntar acerca del ejercicio y en general, de todo el curso. \n",
    "\n",
    "- Cada sección tiene un punto base y se evalúa sobre 6 puntos.\n",
    "\n",
    "- Al revisar, tu código será ejecutado. Verifica que tu entrega no tenga errores.\n",
    "\n",
    "\n",
    "## Referencias   \n",
    "\n",
    "Vídeos: \n",
    "\n",
    "- [Linear Models](https://youtu.be/zhBxDsNLZEA)\n",
    "- [Neural Networks](https://youtu.be/oHZHA8h2xN0)\n",
    "- [Word Embeddings](https://youtu.be/wtwUsJMC9CA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G4wYf0vgnbTv"
   },
   "source": [
    "## Preguntas Teóricas\n",
    "Para estas preguntas no es necesario implementar código, pero pueden utilizar pseudo código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5hUG6-8ngoK"
   },
   "source": [
    "### Parte 1: Modelos Lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5yRvZbhsoi8f"
   },
   "source": [
    "Suponga que tiene un dataset de 10.000 documentos etiquetados por 4 categorías: política, deporte, negocios y otros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "irsqBVmCnx3M"
   },
   "source": [
    "**Pregunta 1**: Diseñe un modelo lineal capaz de clasificar un documento según estas categorías donde el output sea un vector con una distribución de probabilidad con la pertenencia a cada clase. (3 puntos)\n",
    "\n",
    "**Respuesta**: \n",
    "\n",
    "Representación escogida del documento de entrada:\n",
    "\n",
    "Parámetros del modelo:\n",
    "\n",
    "Transformaciones necesarias:\n",
    "\n",
    "Función de pérdida escogida:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5FaWqBVvL90"
   },
   "source": [
    "**Pregunta 2**: Explique el proceso de entrenamiento y evaluación del modelo. (3 puntos)\n",
    "\n",
    "**Respuesta**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkK7pc54njZq"
   },
   "source": [
    "### Parte 2: Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUbJjlj_9AFC"
   },
   "source": [
    "Supongamos que tenemos la siguiente red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obUfuOYB_TOC"
   },
   "source": [
    "![Red](https://drive.google.com/uc?id=1Yd0s9g5SlB1-XuVokGQO2J-yDudQe2Kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2z-8zKW0_6q"
   },
   "source": [
    "**Pregunta 1**: En clases les explicaron como se puede representar una red neuronal de una y dos capas de manera matemática. Dada la red neuronal anterior, represéntela matemáticamente, entregando las dimensiones de las matrices y vectores. (3 Puntos)\n",
    "\n",
    "**Respuesta**: \n",
    "\n",
    "Formula:\n",
    "$\\vec{\\hat{y}} = NN_{MLP3}(\\vec{x}) =$\n",
    "\n",
    "**Pregunta 2**: Qué es backpropagation? Cuales serían los parámetros a evaluar en la red neuronal anterior? (1 punto)\n",
    "\n",
    "**Respuesta**:\n",
    "\n",
    "**Pregunta 3**: Explique los pasos de backpropagation. En la red neuronal anterior: Cuales son las derivadas que debemos calcular para poder obtener $\\vec{\\delta^l_{[j]}}$ en todas las capas? (2 puntos)\n",
    "\n",
    "**Respuesta**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocS_vQhR1gcU"
   },
   "source": [
    "## Pregunta Práctica:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ol82nJ0FnmcP"
   },
   "source": [
    "### Parte 3: Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OgmeSFqKLpFL"
   },
   "source": [
    "En la auxiliar 2 aprendieron como entrenar Word2Vec utilizando gensim. El objetivo de esta parte es comparar los embeddings obtenidos con dos modelos diferentes: Word2Vec y [FastText](https://radimrehurek.com/gensim/models/fasttext.html) (utilizen size=200 en FastText) entrenados en el mismo dataset de diálogos de los Simpson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecCvnryeQiG7"
   },
   "outputs": [],
   "source": [
    "import re  \n",
    "import pandas as pd \n",
    "from time import time  \n",
    "from collections import defaultdict \n",
    "import string \n",
    "import multiprocessing\n",
    "import os\n",
    "import gensim\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, cohen_kappa_score, classification_report\n",
    "\n",
    "# word2vec\n",
    "from gensim.models import Word2Vec, KeyedVectors, FastText\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZgN06q4QPi3"
   },
   "source": [
    "Utilizando el dataset adjunto con la tarea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eY3kmg4onnsu"
   },
   "outputs": [],
   "source": [
    "data_file = \"dialogue-lines-of-the-simpsons.zip\"\n",
    "df = pd.read_csv(data_file)\n",
    "stopwords = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/Alir3z4/stop-words/master/english.txt'\n",
    ").values\n",
    "stopwords = Counter(stopwords.flatten().tolist())\n",
    "df = df.dropna().reset_index(drop=True) # Quitar filas vacias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VAg5a5bmWk3T"
   },
   "source": [
    "**Pregunta 1**: Ayudándose de los pasos vistos en la auxiliar, entrene los modelos Word2Vec y FastText sobre el dataset anterior. (4 puntos) (Hint, le puede servir explorar un poco los datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWw2fXFRXe5Y"
   },
   "source": [
    "**Respuesta**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YILUICGtYJo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oos6kUF5tYJr"
   },
   "source": [
    "**Pregunta 2**: Encuentre las palabras mas similares a las siguientes: Lisa, Bart, Homer, Marge. Cúal es la diferencia entre ambos resultados? Por qué ocurre esto? Intente comparar ahora Liisa en ambos modelos (doble i). Cuando escogería uno vs el otro? (2 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wqX03jStYJr"
   },
   "source": [
    "**Respuesta**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3ovjW6WtYJr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XAbldwNFtYJu"
   },
   "source": [
    "### Parte 4: Aplicar embeddings para clasificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5DlKSestYJu"
   },
   "source": [
    "Ahora utilizaremos estos embeddings para clasificar palabras basadas en su polaridad (positivas o negativas). Para esto ocuparemos el lexicón AFINN incluido en la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCDFYm_ytYJu"
   },
   "outputs": [],
   "source": [
    "AFINN = 'AFINN_full.csv'\n",
    "df_afinn = pd.read_csv(AFINN, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-icASpvytYJw"
   },
   "source": [
    "Hint: Para w2v son esperables KeyErrors, para eso pueden utilizar esta función auxiliar para filtrar las filas en el dataframe que no tienen embeddings (como w2v no tiene token UNK se deben ignorar), para luego aplicar los embeddings en toda la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXw9CGmgtYJx"
   },
   "outputs": [],
   "source": [
    "def try_apply(model,word):\n",
    "    try:\n",
    "        aux = model[word]\n",
    "        return True\n",
    "    except KeyError:\n",
    "        #logger.error('Word {} not in dictionary'.format(word))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8d8qtIgtYJy"
   },
   "source": [
    "**Pregunta 1**: Una vez que tengan un dataframe del estilo [embedding, sentimiento] para ambos modelos, separarlo utilizando la siguiente función, donde X es su columna de embeddings e y es la columna de los valores. (3 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_frb5aDatYJz"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Dw6KBAftYJ1"
   },
   "source": [
    "**Respuesta**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmrrkpaStYJ1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u33__LaNtYJ3"
   },
   "source": [
    "**Pregunta 2**: Entrenar una regresión logística (vista en auxiliar) y reportar accuracy, precision, recall, f1 y confusion_matrix para ambos modelos. Por qué se obtienen estos resultados? Cómo los mejorarías? (3 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dP5zYH3qtYJ3"
   },
   "source": [
    "**Respuesta**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gOt6N4nftYJ4"
   },
   "source": [
    "# Bonus: 2 puntos en cualquier pregunta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnsV0J6StYJ4"
   },
   "source": [
    "**Pregunta 1**: Replicar la parte anterior utilizando embeddings pre-entrenados en un dataset más grande y obtener mejores resultados. Les puede servir [ésta](https://radimrehurek.com/gensim/downloader.html#module-gensim.downloader) documentacion de gensim (1 punto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7lYudsa_tYJ4"
   },
   "source": [
    "**Respuesta**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sd4psA7LtYJ5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DrZxZZfutYJ7"
   },
   "source": [
    "**Pregunta 2**: Utilizar wefe para ver si el modelo w2v entrenado con los dialogos de los Simpson tienen algun bias entre los personajes hombres y la cerveza (1 punto):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Subk47EatYJ7"
   },
   "source": [
    "**Respuesta**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgThotyEtYJ7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Minitarea3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
